{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63418dd2",
   "metadata": {
    "papermill": {
     "duration": 0.00475,
     "end_time": "2023-05-27T20:07:27.777683",
     "exception": false,
     "start_time": "2023-05-27T20:07:27.772933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How well can we do with just a fixed prediction?\n",
    "\n",
    "The goal of this notebook is two-fold:\n",
    "1. Understanding the _baseline_ performance on the task: the normalised Levenshtein distance is unusual and I wanted to get a feel for what the minimum reasonable LB score is. **Understanding the metric is vital to understand how to build the best models.**\n",
    "2. Understanding the minimum possible submission. This is my first time using TFLite, and so making this baseline helped understand what steps are needed.\n",
    "\n",
    "Thank you to @wonderingalice for their minimal submission notebook! https://www.dataset.com/code/wonderingalice/working-sample-submission-and-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c469cf39",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-27T20:07:27.789169Z",
     "iopub.status.busy": "2023-05-27T20:07:27.788509Z",
     "iopub.status.idle": "2023-05-27T20:07:39.729425Z",
     "shell.execute_reply": "2023-05-27T20:07:39.728151Z"
    },
    "papermill": {
     "duration": 11.949608,
     "end_time": "2023-05-27T20:07:39.732043",
     "exception": false,
     "start_time": "2023-05-27T20:07:27.782435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 2.12.0\n",
      "Python 3.10.10\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, constraints, regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "!python --version\n",
    "\n",
    "basedir = \"/dataset/working/\"\n",
    "NUM_CHARACTERS = 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a23555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:07:39.745271Z",
     "iopub.status.busy": "2023-05-27T20:07:39.743323Z",
     "iopub.status.idle": "2023-05-27T20:07:39.963114Z",
     "shell.execute_reply": "2023-05-27T20:07:39.961994Z"
    },
    "papermill": {
     "duration": 0.228854,
     "end_time": "2023-05-27T20:07:39.965650",
     "exception": false,
     "start_time": "2023-05-27T20:07:39.736796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/dataset/input/asl-fingerspelling/train.csv')\n",
    "# Dummy features: we don't actually use any features\n",
    "SEL_FEATURES = ['x_right_hand_0','y_right_hand_0']\n",
    "\n",
    "c2p = json.load(open('/dataset/input/asl-fingerspelling/character_to_prediction_index.json', 'r'))\n",
    "p2c = {p: c for c, p in c2p.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6aa28",
   "metadata": {
    "papermill": {
     "duration": 0.004241,
     "end_time": "2023-05-27T20:07:39.974447",
     "exception": false,
     "start_time": "2023-05-27T20:07:39.970206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finding the best constant prediction\n",
    "\n",
    "[Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) gives us the smallest number of insertions, deletions and **substitutions** possible between our predicted string as the actual string.\n",
    "\n",
    "**There's a subtle point here:** a substitution is the same as a deletion, so if we know the average string has 12 characters, it makes sense to predict 12 characters. Any character you predict which ends up in the actual string gets you a point, while any character you mis-predict gets you the same as if you made no prediction. \n",
    "\n",
    "This is different to other metrics that incorporate recall, where over-predicting can harm you.\n",
    "\n",
    "To find the \"average\" string, which has the shortest distance to all the strings in the dataset, we use a greedy algorithm. We start with the empty string, and repeatedly find the best single character to insert _anywhere_ in the string, until we can no longer improve the training score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1de033a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:07:39.985674Z",
     "iopub.status.busy": "2023-05-27T20:07:39.984936Z",
     "iopub.status.idle": "2023-05-27T20:12:32.960060Z",
     "shell.execute_reply": "2023-05-27T20:12:32.958464Z"
    },
    "papermill": {
     "duration": 292.992385,
     "end_time": "2023-05-27T20:12:32.971236",
     "exception": false,
     "start_time": "2023-05-27T20:07:39.978851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best @ 1=\" \", score 0.0246\n",
      "New best @ 1=\"a\", score 0.0324\n",
      "Best str @ 1=\"a\", score 0.0324\n",
      "New best @ 2=\" a\", score 0.0549\n",
      "New best @ 2=\"ea\", score 0.0563\n",
      "New best @ 2=\"ae\", score 0.0588\n",
      "Best str @ 2=\"ae\", score 0.0588\n",
      "New best @ 3=\" ae\", score 0.0802\n",
      "Best str @ 3=\" ae\", score 0.0802\n",
      "New best @ 4=\"  ae\", score 0.0896\n",
      "New best @ 4=\"- ae\", score 0.0966\n",
      "New best @ 4=\" oae\", score 0.0970\n",
      "New best @ 4=\" aoe\", score 0.0974\n",
      "New best @ 4=\" are\", score 0.0982\n",
      "Best str @ 4=\" are\", score 0.0982\n",
      "New best @ 5=\"  are\", score 0.1052\n",
      "New best @ 5=\"- are\", score 0.1134\n",
      "Best str @ 5=\"- are\", score 0.1134\n",
      "New best @ 6=\" - are\", score 0.1209\n",
      "New best @ 6=\"-- are\", score 0.1259\n",
      "New best @ 6=\"-e are\", score 0.1262\n",
      "Best str @ 6=\"-e are\", score 0.1262\n",
      "New best @ 7=\" -e are\", score 0.1356\n",
      "New best @ 7=\"a-e are\", score 0.1364\n",
      "New best @ 7=\"-e- are\", score 0.1382\n",
      "New best @ 7=\"-e -are\", score 0.1385\n",
      "Best str @ 7=\"-e -are\", score 0.1385\n",
      "New best @ 8=\" -e -are\", score 0.1464\n",
      "New best @ 8=\"a-e -are\", score 0.1476\n",
      "Best str @ 8=\"a-e -are\", score 0.1476\n",
      "New best @ 9=\" a-e -are\", score 0.1562\n",
      "Best str @ 9=\" a-e -are\", score 0.1562\n",
      "New best @ 10=\"+ a-e -are\", score 0.1563\n",
      "New best @ 10=\"1 a-e -are\", score 0.1581\n",
      "New best @ 10=\"2 a-e -are\", score 0.1588\n",
      "New best @ 10=\" ao-e -are\", score 0.1592\n",
      "New best @ 10=\" a-e -aroe\", score 0.1599\n",
      "Best str @ 10=\" a-e -aroe\", score 0.1599\n",
      "New best @ 11=\"2 a-e -aroe\", score 0.1602\n",
      "Best str @ 11=\"2 a-e -aroe\", score 0.1602\n",
      "No improvement, best is 2 a-e -aroe\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import distance\n",
    "ally = df_train['phrase'].values\n",
    "totaly = sum([len(y) for y in ally])\n",
    "\n",
    "# Evaluate a constant prediction on the training set\n",
    "def eval_string(s):\n",
    "    d = 0\n",
    "    for y in ally:\n",
    "        d += distance(s, y)\n",
    "    return (totaly - d) / totaly\n",
    "\n",
    "# Greedy algorithm\n",
    "best_str = ''\n",
    "best_score = 0\n",
    "chars = list(c2p.keys())\n",
    "\n",
    "for i in range(20): # max length\n",
    "    inner_best = best_str\n",
    "    inner_best_score = best_score\n",
    "    \n",
    "    for position in range(len(best_str)+1): # at all insertion points\n",
    "        for newchar in chars:               # try all characters\n",
    "            new_str = best_str[:position] + str(newchar) + best_str[position:]\n",
    "            score = eval_string(new_str)\n",
    "\n",
    "            if score > inner_best_score:\n",
    "                inner_best = new_str\n",
    "                inner_best_score = score\n",
    "                print(f'New best @ {len(inner_best)}=\"{inner_best}\", score {inner_best_score:.4f}')\n",
    "\n",
    "    if best_score >= inner_best_score:\n",
    "        print('No improvement, best is', best_str)\n",
    "        break\n",
    "        \n",
    "    best_str = inner_best\n",
    "    best_score = inner_best_score\n",
    "    print(f'Best str @ {len(best_str)}=\"{best_str}\", score {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f96573",
   "metadata": {
    "papermill": {
     "duration": 0.008294,
     "end_time": "2023-05-27T20:12:32.986905",
     "exception": false,
     "start_time": "2023-05-27T20:12:32.978611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Turning this into a TFLite model\n",
    "\n",
    "I found that the path of least resistance here was to turn this constant prediction into a Keras model, and then convert that into TFLie. It's unclear to me what operations are allowed in TFLite models, but this provides a framework for embedding any code you might want into an arbitrary Keras layer.\n",
    "\n",
    "It appears that dataset's evalution work like this:\n",
    "- Your model is run **once per video** in the test set (each video is one batch).\n",
    "- You receive an input of shape `(N_FRAMES, N_FEATURES)`. The normal \"time-series\" way of doing this would be `(1, N_FRAMES, N_FEATURES)`, so note this is different.\n",
    "- You return an output of shape `(N_CHARS, 59)` where 59 is the number of possible characters. `N_CHARS` is up to your model, in our case it's constant.\n",
    "- Evaluation is done on **the argmax of your predictions**, so it doesn't matter what the actual probability is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ef56e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:12:33.006789Z",
     "iopub.status.busy": "2023-05-27T20:12:33.006044Z",
     "iopub.status.idle": "2023-05-27T20:12:33.012177Z",
     "shell.execute_reply": "2023-05-27T20:12:33.011078Z"
    },
    "papermill": {
     "duration": 0.019455,
     "end_time": "2023-05-27T20:12:33.015315",
     "exception": false,
     "start_time": "2023-05-27T20:12:32.995860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "const_pred = np.zeros((len(best_str), 59))\n",
    "for i, c in enumerate(best_str):\n",
    "    const_pred[i, c2p[c]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3df92bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:12:33.032788Z",
     "iopub.status.busy": "2023-05-27T20:12:33.032316Z",
     "iopub.status.idle": "2023-05-27T20:12:33.042617Z",
     "shell.execute_reply": "2023-05-27T20:12:33.041287Z"
    },
    "papermill": {
     "duration": 0.023441,
     "end_time": "2023-05-27T20:12:33.046217",
     "exception": false,
     "start_time": "2023-05-27T20:12:33.022776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the custom layer\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "class ConstantLayer(Layer):\n",
    "    def __init__(self, constant_vector, name=None):\n",
    "        super(ConstantLayer, self).__init__(name=name)\n",
    "        self.constant_vector = tf.Variable(initial_value=constant_vector, trainable=False, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.constant_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "668aa77c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:12:33.063000Z",
     "iopub.status.busy": "2023-05-27T20:12:33.062543Z",
     "iopub.status.idle": "2023-05-27T20:12:33.272109Z",
     "shell.execute_reply": "2023-05-27T20:12:33.270086Z"
    },
    "papermill": {
     "duration": 0.221683,
     "end_time": "2023-05-27T20:12:33.275332",
     "exception": false,
     "start_time": "2023-05-27T20:12:33.053649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(len(SEL_FEATURES),), name='inputs')  # Let's assume we are inputting vectors of size 10\n",
    "output_layer = ConstantLayer(const_pred, name='outputs')(input_layer)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3884da4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T20:12:33.293717Z",
     "iopub.status.busy": "2023-05-27T20:12:33.293284Z",
     "iopub.status.idle": "2023-05-27T20:12:35.705231Z",
     "shell.execute_reply": "2023-05-27T20:12:35.703608Z"
    },
    "papermill": {
     "duration": 2.424788,
     "end_time": "2023-05-27T20:12:35.708586",
     "exception": false,
     "start_time": "2023-05-27T20:12:33.283798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: ./inference_args.json\r\n",
      "  adding: model.tflite (deflated 86%)\r\n"
     ]
    }
   ],
   "source": [
    "tflite_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "model_path = 'model.tflite'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "!zip submission.zip  './model.tflite' './inference_args.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9279ef1",
   "metadata": {
    "papermill": {
     "duration": 0.007777,
     "end_time": "2023-05-27T20:12:35.723740",
     "exception": false,
     "start_time": "2023-05-27T20:12:35.715963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Overall, we see 0.160 on CV, and 0.157 on LB - pretty consistent!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 325.010304,
   "end_time": "2023-05-27T20:12:39.034059",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-27T20:07:14.023755",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
