{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"background-color:#ffffff;font-family:candaralight;color:#C15D06;font-size:215%;text-align:center;border-radius:10px 10px;\"> Google ASL Fingerspelling</p>\n",
    "<p style=\"background-color:#ffffff;font-family:candaralight;color:#B0B0B0;font-size:150%;text-align:center;border-radius:10px 10px;\">‚úã Recognition and Visualization ‚úã</p>\n",
    "\n",
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://media1.giphy.com/media/Co5TKVg51CmFsxPpNP/giphy.webp\" alt=\"Heat beating\" > </div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Welcome to my notebook for the ASL Fingerspelling Recognition dataset competition! In this notebook, I present my solution for detecting and translating American Sign Language (ASL) fingerspelling into text. Using deep learning techniques, I have trained a model on the largest dataset of its kind, consisting of over three million fingerspelled characters captured from smartphone selfie cameras.\n",
    "\n",
    " My aim is to contribute to the advancement of sign language recognition technology and make AI more accessible for the Deaf and Hard of Hearing community. With the potential to enable faster and smoother communication between the Deaf and Hard of Hearing individuals and hearing non-signers, this work has the power to create a positive impact.\n",
    "\n",
    "I hope that my notebook will showcase the effectiveness of my approach and provide insights into the development of robust sign language recognition AI. I am excited to present my solution and contribute to the empowerment of the Deaf and Hard of Hearing community through innovative machine learning techniques.\n",
    "\n",
    "Wish me luck as I embark on this journey!\n",
    "        \n",
    " **<span style=\"color:darkorange;\"> If you liked this Notebook, please do forget to upvote, and GooD LucK.</span>**\n",
    "\n",
    "   <center><div class=\"alert alert-block alert-warning\" style=\"margin: 2em; line-height: 1.7em; font-family: candaralight;\">\n",
    "    <b style=\"font-size: 18px;\">üëè &nbsp; IF YOU FORK THIS OR FIND THIS HELPFUL &nbsp; üëè</b><br><br><b style=\"font-size: 22px; color: darkorange\">PLEASE UPVOTE!</b><br><br>This was a lot of work for me and while it may seem silly, it makes me feel appreciated when others like my work. üòÖ\n",
    "</div></center>\n",
    "    \n",
    "\n",
    "<p id=\"toc\"></p>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">TABLE OF CONTENTS</h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Model Architecture\n",
    "    3.1 Convolutional Neural Network (CNN)\n",
    "    3.2 Long Short-Term Memory (LSTM)\n",
    "    3.3 Model Fusion\n",
    "4. Model Training\n",
    "    4.1 Training Strategy\n",
    "    4.2 Hyperparameter Tuning\n",
    "    4.3 Transfer Learning\n",
    "5. Evaluation Metrics\n",
    "    5.1 Accuracy\n",
    "    5.2 Precision, Recall, and F1 Score\n",
    "    5.3 Confusion Matrix\n",
    "6. Results and Analysis\n",
    "    6.1 Performance on Training Set\n",
    "    6.2 Performance on Validation Set\n",
    "    6.3 Performance on Test Set\n",
    "7. Model Optimization\n",
    "    7.1 Fine-tuning\n",
    "    7.2 Regularization Techniques\n",
    "    7.3 Ensemble Methods\n",
    "8. Conclusion and Future Work\n",
    "    8.1 Summary of Findings\n",
    "    8.2 Implications and Applications\n",
    "    8.3 Areas for Improvement\n",
    "9. References\n",
    "10. Appendix\n",
    "    10.1 Data Preprocessing Code\n",
    "    10.2 Model Architecture Code\n",
    "    10.3 Training Code\n",
    "    10.4 Evaluation Code\n",
    "    10.5 Additional Experiment Results\n",
    "    \n",
    "* [1. DATA OVERVIEW](#1)\n",
    "    \n",
    "    - [Import Libraries](#1.1)\n",
    "    \n",
    "    - [Loading dataset](#1.2)\n",
    "    \n",
    "    - [Data Description](#1.3)\n",
    "        \n",
    "* [2. Data Preprocessing](#2)   \n",
    "\n",
    "    - [Data Exploration](#2.1)      \n",
    "        \n",
    "    - [Data Cleaning](#2.2)\n",
    "\n",
    "* [3. Feature Engineering](#3)\n",
    "    \n",
    "    - [Define a function to add new features to the data](#3.1)\n",
    "\n",
    "    - [Apply the function](#3.2)\n",
    "\n",
    "* [4. Exploratory Data Analysis](#4)\n",
    "    \n",
    "    - [Define a function to add new features to the data](#4.1)\n",
    "\n",
    "    - [Apply the function](#4.2) \n",
    "* [5. Modeling](#4)\n",
    "    \n",
    "    - [Baseline Model](#5.1)\n",
    "\n",
    "    - [Linear Regression Model](#5.2) \n",
    "    \n",
    "    - [Support Vector Regression Model](#5.3) \n",
    "\n",
    "    - [Random Forest Regression Model](#5.4) \n",
    "\n",
    "    - [LSTM Model](#5.5) \n",
    "\n",
    "* [6. Model Evaluation and Comparison](#6)\n",
    "    \n",
    "* [7. Conclusion](#7)\n",
    "\n",
    "\n",
    "<p id=\"1\"></p>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">1. DATA OVERVIEW</h1>\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we will be exploring and analyzing the Apple stock prices dataset. We will start by importing important libraries, loading the data, and giving a brief description of the dataset.\n",
    "\n",
    "<a id=\"1.1\"></a>\n",
    "<br>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">1.1 <b>Import</b> Libraries</h3>\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# import the desired packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"simple_white\"\n",
    "\n",
    "# import data processing and visualisation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import image processing libraries\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "# import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "print(\"Packages imported...\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:34.580036Z",
     "iopub.execute_input": "2023-06-16T19:41:34.580412Z",
     "iopub.status.idle": "2023-06-16T19:41:37.900399Z",
     "shell.execute_reply.started": "2023-06-16T19:41:34.580382Z",
     "shell.execute_reply": "2023-06-16T19:41:37.895652Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransform\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resize\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# import tensorflow and keras\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/__init__.py:36\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtraceback\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# import it in modules_with_exports.py instead.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 62\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tensorflow_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Let's load the training and supplemental_metadata dataframe\n",
    "<a id=\"1.2\"></a>\n",
    "\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">1.2 <b>Loading</b> Dataset</h3>\n",
    "\n",
    "---\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/dataset/input/asl-fingerspelling/train.csv\")\n",
    "metadata = pd.read_csv(\"/dataset/input/asl-fingerspelling/supplemental_metadata.csv\")\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.901486Z",
     "iopub.status.idle": "2023-06-16T19:41:37.901874Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.901686Z",
     "shell.execute_reply": "2023-06-16T19:41:37.901716Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"1.3\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">1.3 <b>Data</b> Description</h3>\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.903277Z",
     "iopub.status.idle": "2023-06-16T19:41:37.904009Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.903726Z",
     "shell.execute_reply": "2023-06-16T19:41:37.903752Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The phrases in the training set contains random websites/addresses/phone numbers.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total number of files : {df.shape[0]}\")\n",
    "print(f\"Total number of Participant in the dataset : {df.participant_id.nunique()}\")\n",
    "print(f\"Total number of unique phrases : {df.phrase.nunique()}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.905804Z",
     "iopub.status.idle": "2023-06-16T19:41:37.906249Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.906021Z",
     "shell.execute_reply": "2023-06-16T19:41:37.906042Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metadata.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.907638Z",
     "iopub.status.idle": "2023-06-16T19:41:37.908429Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.908189Z",
     "shell.execute_reply": "2023-06-16T19:41:37.908211Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " the metadata phrases are mostly normal sentences!\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "    path - The path to the landmark file.\n",
    "    file_id - A unique identifier for the data file.\n",
    "    participant_id - A unique identifier for the data contributor.\n",
    "    sequence_id - A unique identifier for the landmark sequence. Each data file may contain many sequences.\n",
    "    phrase - The labels for the landmark sequence. The train and test datasets contain randomly generated addresses, phone numbers, and urls derived from components of real addresses/phone numbers/urls. Any overlap with real addresses, phone numbers, or urls is purely accidental. The supplemental dataset consists of fingerspelled sentences. Note that some of the urls include adult content. The intent of this competition is to support the Deaf and Hard of Hearing community in engaging with technology on an equal footing with other adults.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total number of files in metadata: {metadata.shape[0]}\")\n",
    "print(f\"Total number of participants in metadata : {metadata.participant_id.nunique()}\")\n",
    "print(f\"Total number of unique phrases in metadata : {metadata.phrase.nunique()}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.909981Z",
     "iopub.status.idle": "2023-06-16T19:41:37.910609Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.910376Z",
     "shell.execute_reply": "2023-06-16T19:41:37.910398Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets dig deeper into the dataframe info "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Check the dimensions of the dataset\n",
    "df.shape\n",
    "\n",
    "# Check the data types of columns\n",
    "df.info()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.912071Z",
     "iopub.status.idle": "2023-06-16T19:41:37.913011Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.912742Z",
     "shell.execute_reply": "2023-06-16T19:41:37.912772Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.914479Z",
     "iopub.status.idle": "2023-06-16T19:41:37.914959Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.914734Z",
     "shell.execute_reply": "2023-06-16T19:41:37.914757Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p id=\"2\"></p>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">2. DATA PREPROCESSING</h1>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"2.1\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">2.1 Data <b>Exploration</b> </h3>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Dataset Summary Statistics:\")\n",
    "df.describe()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.917318Z",
     "iopub.status.idle": "2023-06-16T19:41:37.918360Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.918105Z",
     "shell.execute_reply": "2023-06-16T19:41:37.918138Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Metadata Summary Statistics:\")\n",
    "metadata.describe()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.919576Z",
     "iopub.status.idle": "2023-06-16T19:41:37.920403Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.920162Z",
     "shell.execute_reply": "2023-06-16T19:41:37.920185Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"2.2\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">2.2 Data <b>Cleaning</b></h3>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.921941Z",
     "iopub.status.idle": "2023-06-16T19:41:37.922723Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.922472Z",
     "shell.execute_reply": "2023-06-16T19:41:37.922494Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df.isnull().any(axis=1)]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.924091Z",
     "iopub.status.idle": "2023-06-16T19:41:37.924884Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.924635Z",
     "shell.execute_reply": "2023-06-16T19:41:37.924657Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p id=\"3\"></p>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">3. EXPLORATORY DATA ANALYSIS</h1>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3.1\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">3.1 Inspect the <b>'PATH'</b> Column</h3>\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "np.array(list(df[\"path\"].value_counts().to_dict().values())).min()\n",
    "df[\"path\"].describe().to_frame().T"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.926273Z",
     "iopub.status.idle": "2023-06-16T19:41:37.927067Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.926830Z",
     "shell.execute_reply": "2023-06-16T19:41:37.926853Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The path column is simply the path to the landmark file (parquet).\n",
    "<ul>\n",
    "    <li><b>Number unique paths</b>: 68</li>\n",
    "    <li><b>Minimum Number of repeated path is</b>: 287</li>\n",
    "    <li><b>Maximum Number of repeated path is</b>: 1000</li>\n",
    "</ul>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3.2\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">3.2 Inspect the <b>`PARTICIPANT_ID`</b> Column</h3>\n",
    "\n",
    "---\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "print(\"\\n... BASICS OF THE PARTICIPANT ID COLUMN:\\n\")\n",
    "df[\"participant_id\"].astype(str).describe().to_frame().T"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.928499Z",
     "iopub.status.idle": "2023-06-16T19:41:37.930056Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.929809Z",
     "shell.execute_reply": "2023-06-16T19:41:37.929832Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The participant_id statistics indicate a varied distribution of data contributions among participants, with some participants contributing more examples than others.\n",
    "\n",
    "<ul>\n",
    "    <li><b>Number of Unique Participants</b>: 94</li>\n",
    "    <li><b>Average Number of Rows Per Participant</b>: 715.82</li>\n",
    "    <li><b>Standard Deviation in Counts Per Participant</b>: 230.86</li>\n",
    "    <li><b>Minimum Number of Examples For One Participant</b>: 1</li>\n",
    "    <li><b>Maximum Number of Examples For One Participant</b>: 1537</li>\n",
    "</ul>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#The column is set to strings as it is an ID\n",
    "df[\"participant_id\"] = df[\"participant_id\"].astype(str)\n",
    "\n",
    "# Calculate the counts for each participant_id\n",
    "counts = df[\"participant_id\"].value_counts()\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Plot the histogram\n",
    "bars = ax.bar(counts.index, counts.values, color=color_scheme[1])\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel(\"Participant ID\")\n",
    "ax.set_ylabel(\"Total Row Count\")\n",
    "ax.set_title(\"Row Counts by Participant ID\")\n",
    "\n",
    "# Rotate the x-axis labels if needed\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "plt.xlim(-1, 94)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.931400Z",
     "iopub.status.idle": "2023-06-16T19:41:37.932193Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.931948Z",
     "shell.execute_reply": "2023-06-16T19:41:37.931971Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3.3\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">3.3 Inspect the <b>`SEQUENCE_ID`</b> Column</h3>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"sequence_id\"].astype(str).describe().to_frame().T"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.933552Z",
     "iopub.status.idle": "2023-06-16T19:41:37.934324Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.934087Z",
     "shell.execute_reply": "2023-06-16T19:41:37.934109Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A unique identifier for the landmark sequence. Each data file may contain many sequences. Every value is unique for every row\n",
    "\n",
    "<a id=\"3.4\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">3.4 Inspect the <b>`PHASES`</b> Column</h3>\n",
    "\n",
    "---\n",
    "\n",
    "How long are the phrases?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df['phrase_len'] = df.phrase.str.len()\n",
    "metadata['phrase_len'] = metadata.phrase.str.len()\n",
    "\n",
    "for param in ['text.color', 'axes.labelcolor', 'xtick.color', 'ytick.color']:\n",
    "    plt.rcParams[param] = '#000000'  # very light grey\n",
    "\n",
    "for param in ['figure.facecolor', 'axes.facecolor', 'savefig.facecolor']:\n",
    "    plt.rcParams[param] = '#ffffff'  # bluish dark grey\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 7), tight_layout=True)\n",
    "\n",
    "# Remove axes splines\n",
    "for s in ['top', 'bottom', 'left', 'right']:\n",
    "    axs.spines[s].set_visible(False)\n",
    "\n",
    "# Remove x, y ticks\n",
    "axs.xaxis.set_ticks_position('none')\n",
    "axs.yaxis.set_ticks_position('none')\n",
    "\n",
    "# Add padding between axes and labels\n",
    "axs.xaxis.set_tick_params(pad=5)\n",
    "axs.yaxis.set_tick_params(pad=10)\n",
    "\n",
    "# Add x, y gridlines\n",
    "axs.grid(b=True, color='grey', linestyle='-.', linewidth=0.5, alpha=0.6)\n",
    "\n",
    "# Set the custom color scheme\n",
    "color_scheme = [\"#4f000b\", \"#720026\", \"#ce4257\", \"#ff7f51\", \"#ff9b54\"]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df.phrase_len, kde=True, binwidth = 2, color=color_scheme[0])\n",
    "plt.title('Character occurences in each phrase in training set')\n",
    "plt.xlabel('Phrase length')\n",
    "plt.ylabel('Sample Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(metadata.phrase_len, kde=True, binwidth = 2, color=color_scheme[0])\n",
    "plt.title('    and Supplementary metadata')\n",
    "plt.xlabel('Unique characters')\n",
    "plt.ylabel('Sample Count')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.935801Z",
     "iopub.status.idle": "2023-06-16T19:41:37.936567Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.936328Z",
     "shell.execute_reply": "2023-06-16T19:41:37.936351Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3.3\"></a>\n",
    "\n",
    "<h3 style=\"font-family: candaralight; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #C15D06; background-color: #ffffff;\">3.3 Inspect the <b>`PARQUET`</b> Column</h3>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "sample = pd.read_parquet(\"/dataset/input/asl-fingerspelling/train_landmarks/1019715464.parquet\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.937940Z",
     "iopub.status.idle": "2023-06-16T19:41:37.938734Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.938456Z",
     "shell.execute_reply": "2023-06-16T19:41:37.938478Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Sample shape = {sample.shape}\")\n",
    "sample.sample(10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.940114Z",
     "iopub.status.idle": "2023-06-16T19:41:37.940882Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.940628Z",
     "shell.execute_reply": "2023-06-16T19:41:37.940651Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample.describe()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.942315Z",
     "iopub.status.idle": "2023-06-16T19:41:37.943126Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.942888Z",
     "shell.execute_reply": "2023-06-16T19:41:37.942910Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "We see a few negative coordinates above. Verbatim from the mediapipe page:\n",
    "\n",
    "    MULTI_HAND_LANDMARKS Collection of detected/tracked hands, where each hand is represented as a list of 21 hand landmarks and each landmark is composed of x, y and z. x and y are normalized to [0.0, 1.0] by the image width and height respectively. z represents the landmark depth with the depth at the wrist being the origin, and the smaller the value the closer the landmark is to the camera. The magnitude of z uses roughly the same scale as x.\n",
    "\n",
    "So negative values are not expected for x and y perhaps. It is also important to note that for a good chunk of the video either or both hands will not be visible or in other words, will not have any landmark data. Check the nulls in the data below:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_cols(df, words_pos, words_neg=[], ret_names=True):\n",
    "    cols = []\n",
    "    names = []\n",
    "    for col in df.columns:\n",
    "        # Check if column name contains all words\n",
    "        if all([w in col for w in words_pos]) and all([w not in col for w in words_neg]):\n",
    "            cols.append(df[col])  # Append the entire column to the list\n",
    "            names.append(col)\n",
    "\n",
    "    # Returns either both columns and names as DataFrame\n",
    "    if ret_names:\n",
    "        return cols, names\n",
    "    # Or only columns as DataFrame\n",
    "    else:\n",
    "        return cols\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.944548Z",
     "iopub.status.idle": "2023-06-16T19:41:37.945329Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.945087Z",
     "shell.execute_reply": "2023-06-16T19:41:37.945110Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Landmark Indices for Left/Right hand without z axis in raw data\n",
    "LEFT_HAND_IDXS0, LEFT_HAND_NAMES0 = get_cols(sample, ['left_hand'], ['z'])\n",
    "RIGHT_HAND_IDXS0, RIGHT_HAND_NAMES0 = get_cols(sample, ['right_hand'], ['z'])\n",
    "#RIGHT_HAND_NAMES0.insert(0, \"frame\")\n",
    "LEFT_HAND_NAMES0.insert(0, \"frame\")\n",
    "COLUMNS = np.concatenate((LEFT_HAND_NAMES0, RIGHT_HAND_NAMES0))\n",
    "\n",
    "N_COLS0 = len(COLUMNS)\n",
    "# Only X/Y axes are used\n",
    "N_DIMS0 = 2\n",
    "\n",
    "print(f'N_COLS0: {N_COLS0}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.946737Z",
     "iopub.status.idle": "2023-06-16T19:41:37.947480Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.947241Z",
     "shell.execute_reply": "2023-06-16T19:41:37.947263Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "RIGHT_HAND = sample.loc[:, RIGHT_HAND_NAMES0] \n",
    "LEFT_HAND = sample.loc[:, LEFT_HAND_NAMES0] \n",
    "RIGHT_HAND\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.948887Z",
     "iopub.status.idle": "2023-06-16T19:41:37.949663Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.949413Z",
     "shell.execute_reply": "2023-06-16T19:41:37.949435Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Percentage of nulls in Left Hand data = {100*np.mean(LEFT_HAND['x_left_hand_0'].isnull()):.02f} %\")\n",
    "print(f\"Percentage of nulls in Right Hand data = {100*np.mean(RIGHT_HAND['x_right_hand_0'].isnull()):.02f} %\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.951037Z",
     "iopub.status.idle": "2023-06-16T19:41:37.951849Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.951553Z",
     "shell.execute_reply": "2023-06-16T19:41:37.951575Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p id=\"4\"></p>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">4. EVALUATION METRIC</h1>\n",
    "\n",
    "The **Levenshtein distance**, also known as the edit distance, quantifies the dissimilarity between two strings by measuring the minimum number of single-character edits (insertions, deletions, or substitutions) required to transform one string into another. This metric provides a valuable measure of how well the predicted ASL sequence matches the ground truth or reference sequence.\n",
    "\n",
    "To calculate the Levenshtein distance for ASL recognition, the predicted ASL sequence and the reference or ground truth sequence are compared character by character. Each character is treated as a token, representing a specific sign or gesture. The Levenshtein distance is then computed by determining the minimum number of edit operations needed to transform the predicted sequence into the reference sequence or vice versa.\n",
    "\n",
    "The evaluation metric for this contest is the normalized total Levenshtein distance. The formula for calculating the metric is as follows:\n",
    "\n",
    "Metric = (N - D) / N\n",
    "\n",
    "Where:\n",
    "\n",
    "    N is the total number of characters in the labels.\n",
    "    D is the total Levenshtein distance.\n",
    "\n",
    "To calculate the metric, you would need the labels data and the predicted sequence. The Levenshtein distance measures the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one sequence into another.\n",
    "\n",
    "In the given context, it seems that the labels are provided in the \"phrase\" column of the [train/supplemental_metadata].csv file. The predicted sequence can be obtained from the landmark data files in the [train/supplemental]_landmarks/ directory.\n",
    "\n",
    "To calculate the total Levenshtein distance, you would need to compare each character in the labels with the corresponding character in the predicted sequence and count the number of edits required.\n",
    "\n",
    "Finally, you can plug the values of N (total characters in the labels) and D (total Levenshtein distance) into the formula to compute the metric. The resulting value will give you an indication of the accuracy of the predicted sequence compared to the labels, with higher values indicating better performance.\n",
    "\n",
    "Note: Since the specific implementation details are not provided, you would need to write code or use existing libraries to calculate the Levenshtein distance and implement the metric calculation\n",
    "\n",
    "the LD is explained in depth in this discussion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from Levenshtein import distance\n",
    "#Using the dynamic programming approach for calculating the Levenshtein distance\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    # Create a 2-D matrix \n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    \n",
    "    #Initialize the first row and column, Row index is fixed to 0 and the variable t1 is used to define the column index. \n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "        \n",
    "    #Column index of the distances array is now fixed to 0, while the loop variable t2 is used to define the index of the rows\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    #Inside the loops the distances are calculated for all combinations of prefixes from the two words. \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "            #If the two characters are not equal, then the distance in the current cell is equal to the\n",
    "            #minimum of the three existing values in the 2 x 2 matrix after adding a cost of 1\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "                    \n",
    "    #Print its contents \n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    \n",
    "    #returning the calculated distance between the two words\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "\n",
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "        \n",
    "phase1 = '3 creekhouse'\n",
    "phase2 = 'scales/kuhaylah'\n",
    "\n",
    "#Calling levenshteinDistanceDP function, \n",
    "#It returns an integer representing the distance between them\n",
    "\n",
    "print(\"Printing The Distance Matrix:\")\n",
    "print(f\" \\nThe Levenshtein distance of phases = {levenshteinDistanceDP(phase1, phase2):.02f} \")\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.953331Z",
     "iopub.status.idle": "2023-06-16T19:41:37.954181Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.953924Z",
     "shell.execute_reply": "2023-06-16T19:41:37.953947Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introduction\n",
    "This notebook is a continuation of the Google ASL Finger Recognition project. In the previous notebook, we processed the data and extracted features for the task. In this notebook, we will train and evaluate a model using the extracted features. Additionally, we will use the Levenshtein distance as a metric to measure the similarity between predicted labels and ground truth labels.\n",
    "\n",
    "Table of Contents\n",
    "Importing Libraries and Levenshtein Distance Implementation\n",
    "Calculating Levenshtein Distance\n",
    "Data Preparation and Splitting\n",
    "Model Definition\n",
    "Optimization Setup\n",
    "Training Loop\n",
    "Evaluation\n",
    "Conclusion\n",
    "Let's proceed with the code implementation and analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p id=\"4\"></p>\n",
    "\n",
    "<h1 style=\"font-family: candaralight; font-size: 28px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #C15D06; background-color: #ffffff;\">4. Visualization</h1>"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-14T19:11:36.105006Z",
     "iopub.execute_input": "2023-06-14T19:11:36.105466Z",
     "iopub.status.idle": "2023-06-14T19:11:36.116436Z",
     "shell.execute_reply.started": "2023-06-14T19:11:36.105426Z",
     "shell.execute_reply": "2023-06-14T19:11:36.115003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### import libraries\n",
    "import pandas as pd,numpy as np,os\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "print(\"importing\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.955585Z",
     "iopub.status.idle": "2023-06-16T19:41:37.956416Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.956175Z",
     "shell.execute_reply": "2023-06-16T19:41:37.956198Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LANDMARK_FILES_DIR = \"/dataset/input/asl-fingerspelling/train_landmarks\"\n",
    "TRAIN_FILE = \"/dataset/input/asl-fingerspelling/train.csv\"\n",
    "label_map = json.load(open(\"/dataset/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\"))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.957831Z",
     "iopub.status.idle": "2023-06-16T19:41:37.958605Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.958364Z",
     "shell.execute_reply": "2023-06-16T19:41:37.958387Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T21:14:56.463506Z",
     "iopub.execute_input": "2023-06-16T21:14:56.463885Z",
     "iopub.status.idle": "2023-06-16T21:14:56.955650Z",
     "shell.execute_reply.started": "2023-06-16T21:14:56.463857Z",
     "shell.execute_reply": "2023-06-16T21:14:56.954021Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LANDMARK_FILES_DIR = \"/dataset/input/asl-fingerspelling/train_landmarks\"\n",
    "TRAIN_FILE = \"/dataset/input/asl-fingerspelling/train.csv\"\n",
    "label_map = json.load(open(\"/dataset/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\"))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.962351Z",
     "iopub.status.idle": "2023-06-16T19:41:37.963149Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.962895Z",
     "shell.execute_reply": "2023-06-16T19:41:37.962919Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Memory saving function credit to https://www.dataset.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    #start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    #end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.964745Z",
     "iopub.status.idle": "2023-06-16T19:41:37.965635Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.965351Z",
     "shell.execute_reply": "2023-06-16T19:41:37.965376Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Function to process a single parquet file\n",
    "def process_parquet(row):\n",
    "    path = os.path.join(\"/dataset/input/asl-fingerspelling\", row[1].path)\n",
    "    data_columns = COLUMNS\n",
    "    landmark_df = pd.read_parquet(path, columns=data_columns)\n",
    "\n",
    "    # Group the landmarks by sequence_id\n",
    "    grouped_landmarks = landmark_df.groupby('sequence_id')\n",
    "\n",
    "    # Initialize empty lists to store features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over each sequence_id\n",
    "    for sequence_id, group in grouped_landmarks:\n",
    "        # Get the label for the sequence\n",
    "        phrase = df.loc[df['sequence_id'] == sequence_id, 'phrase'].iloc[0]\n",
    "\n",
    "        # Map each letter in the phrase using label_map\n",
    "        mapped_phrase = [letter for letter in phrase]\n",
    "        \n",
    "        # Create a new Series with sequence and mapped_phrase\n",
    "        result_series = pd.DataFrame({'sequence_id': sequence_id, 'mapped_phrase': mapped_phrase}) \n",
    "        result_series['label'] = result_series['mapped_phrase'].map(label_map).astype(np.int8)  \n",
    "        \n",
    "        # Convert the label Series to a list\n",
    "        label_list = result_series['label'].tolist()\n",
    "\n",
    "        # Initialize an empty feature vector for the sequence\n",
    "        sequence_features = []\n",
    "        \n",
    "        # Iterate over each landmark index\n",
    "        for landmark_index in range(20):\n",
    "            # Generate feature names for x, y, z coordinates\n",
    "            x_feature = f'x_right_hand_{landmark_index}'\n",
    "            y_feature = f'y_right_hand_{landmark_index}'\n",
    "\n",
    "            # Get the x, y, z coordinates for the landmark\n",
    "            x = group[x_feature].values.astype(np.float16)\n",
    "            y = group[y_feature].values.astype(np.float16)\n",
    "            \n",
    "\n",
    "            # Perform feature transformations or calculations\n",
    "            x = torch.tensor(x).contiguous().view(-1, x.shape[0])\n",
    "            y = torch.tensor(y).contiguous().view(-1, y.shape[0])\n",
    "\n",
    "            x = x[:,~torch.any(torch.isnan(x), dim=0)]\n",
    "            y = y[:,~torch.any(torch.isnan(y), dim=0)]\n",
    "            \n",
    "            x_mean = torch.mean(x, 0) \n",
    "            y_mean = torch.mean(y, 0) \n",
    "\n",
    "            x_std = torch.std(x,1) \n",
    "            y_std = torch.std(y,1) \n",
    "\n",
    "            # Add the calculated features to the sequence feature vector\n",
    "            #sequence_features.extend([x_mean, y_mean, x_std, y_std])\n",
    "            #if x_mean.numel() > 0 or y_mean.numel() > 0 or x_std.numel() > 0 or y_std.numel() > 0:\n",
    "            sequence_features = torch.cat([x_mean,y_mean,x_std,y_std], axis=0)\n",
    "            sequence_features = torch.where(torch.isnan(sequence_features), torch.tensor(0.0, dtype=torch.float32), sequence_features)\n",
    "\n",
    "            diff = 3258 - sequence_features.shape[0]\n",
    "            if (diff >= 0):\n",
    "                padding = torch.zeros(diff)\n",
    "                sequence_features = torch.cat((sequence_features, padding))\n",
    "            features =  sequence_features[:3258].cpu().numpy()\n",
    "            \n",
    "            return features,result_series['label']\n",
    "\n",
    "        # Add the sequence features and label to the overall feature and label lists\n",
    "        #features.append(sequence_features)     \n",
    "        #labels.append(label_list)\n",
    "    \n",
    "    #return np.array(features), np.array(labels)\n",
    "    #return features,labels\n",
    "\n",
    "# Initialize empty lists to store results\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df = reduce_mem_usage(df) \n",
    "df2 = df.head(30)\n",
    "\n",
    "max_label_length = 30\n",
    "all_features = np.zeros((df.shape[0], 3258))\n",
    "labels = np.zeros((df.shape[0], max_label_length))\n",
    "    \n",
    "# Process parquet files in parallel\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.imap(process_parquet, df.iterrows(),  chunksize=250)\n",
    "    for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            #print('x=',x.shape)\n",
    "            all_features[i,:] = x\n",
    "            labels[i,:len(y)] = y.values.reshape(1, -1)\n",
    "\n",
    "    # Unpack results\n",
    "    #for features, labels in results:\n",
    "     #   all_features.extend(features)\n",
    "      #  all_labels.extend(labels)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the result lists to tensors\n",
    "#all_features = [torch.tensor(arr) for arr in all_features]\n",
    "#features_tensor = torch.stack(all_features)\n",
    "\n",
    "# Ensure all the inner lists in labels have the same length\n",
    "#max_length = max(len(inner_list) for inner_list in all_labels)\n",
    "#labels = [inner_list + [0] * (max_length - len(inner_list)) for inner_list in all_labels]\n",
    "#labels_tensor = torch.tensor(labels)\n",
    "\n",
    "# Print the shapes of the tensors\n",
    "np.save(\"feature_data.npy\", all_features)\n",
    "np.save(\"feature_labels.npy\", labels)\n",
    "\n",
    "print(\"Features tensor shape:\", all_features.shape)\n",
    "print(\"Labels tensor shape:\", labels.shape)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.967214Z",
     "iopub.status.idle": "2023-06-16T19:41:37.968020Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.967781Z",
     "shell.execute_reply": "2023-06-16T19:41:37.967804Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "I trained with neural network model using PyTorch. The algorithm used in this code is not explicitly mentioned, but based on the code structure and components, it appears to be a classification task using a neural network with the Adam optimizer and CrossEntropyLoss as the loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "datay = np.load(\"/dataset/input/aslfr-data-processing/feature_labels.npy\")\n",
    "datax = np.load(\"/dataset/input/aslfr-data-processing/feature_data.npy\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T21:15:09.243897Z",
     "iopub.execute_input": "2023-06-16T21:15:09.244290Z",
     "iopub.status.idle": "2023-06-16T21:15:19.072195Z",
     "shell.execute_reply.started": "2023-06-16T21:15:09.244262Z",
     "shell.execute_reply": "2023-06-16T21:15:19.070769Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "datax.shape[1]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.971657Z",
     "iopub.status.idle": "2023-06-16T19:41:37.972480Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.972226Z",
     "shell.execute_reply": "2023-06-16T19:41:37.972249Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "datay.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.973931Z",
     "iopub.status.idle": "2023-06-16T19:41:37.974805Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.974495Z",
     "shell.execute_reply": "2023-06-16T19:41:37.974519Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(ASLModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.layer0 = nn.Linear(3258, 1024)\n",
    "        self.layer1 = nn.Linear(1024, 512)\n",
    "        self.layer2 = nn.Linear(512, 30)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T19:41:37.976226Z",
     "iopub.status.idle": "2023-06-16T19:41:37.977013Z",
     "shell.execute_reply.started": "2023-06-16T19:41:37.976773Z",
     "shell.execute_reply": "2023-06-16T19:41:37.976796Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import Levenshtein\n",
    "\n",
    "def calculate_normalized_levenshtein_distance(pred_strings, target_strings):\n",
    "    total_distance = 0\n",
    "    total_length = 0\n",
    "\n",
    "    for pred, target in zip(pred_strings, target_strings):\n",
    "        distance = Levenshtein.distance(pred, target)\n",
    "        total_distance += distance\n",
    "        total_length += len(target)\n",
    "\n",
    "    normalized_distance = total_distance / total_length\n",
    "    return normalized_distance\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T21:15:24.545161Z",
     "iopub.execute_input": "2023-06-16T21:15:24.545584Z",
     "iopub.status.idle": "2023-06-16T21:15:24.553303Z",
     "shell.execute_reply.started": "2023-06-16T21:15:24.545552Z",
     "shell.execute_reply": "2023-06-16T21:15:24.551402Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import Levenshtein\n",
    "\n",
    "def calculate_levenshtein_distance(pred_labels, target_labels):\n",
    "    distance = 0\n",
    "    for pred, target in zip(pred_labels, target_labels):\n",
    "        distance += Levenshtein.distance(pred, target)\n",
    "    return distance\n",
    "\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, datax, datay):\n",
    "        self.datax = datax\n",
    "        self.datay = datay\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.datax[index,:], self.datay[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datay)\n",
    "    \n",
    "# Data Split\n",
    "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "trainx = torch.from_numpy(trainx).float()\n",
    "trainy = torch.from_numpy(trainy).float()\n",
    "testx = torch.from_numpy(testx).float()\n",
    "testy = torch.from_numpy(testy).float()\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Preparation\n",
    "train_data = ASLDataset(trainx, trainy)\n",
    "test_data = ASLDataset(testx, testy)\n",
    "\n",
    "# DataLoader\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model Definition\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ASLModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, output_size)\n",
    "        #self.dropout = nn.Dropout(0.2)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Model Initialization\n",
    "model = ASLModel(input_size=trainx.shape[1], output_size=trainy.shape[1]).to(device)\n",
    "\n",
    "# Optimization Setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  \n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        #print('targets = ',targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #print('models output = ',outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.round() == targets).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_data)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    levenshtein_distance = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            #print(loss)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (outputs.round() == targets).sum().item()\n",
    "\n",
    "            # Define the reverse mapping dictionary\n",
    "            reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "            outputs_array = outputs.detach().cpu().numpy()\n",
    "            targets_array = targets.detach().cpu().numpy()\n",
    "\n",
    "            # Convert predictions and targets to letter sequences\n",
    "            pred_labels = [[reverse_label_map[label] for label in output.nonzero()[0].tolist()] if len(output.nonzero()[0]) > 0 else [] for output in outputs_array.round()]\n",
    "            target_labels = [[reverse_label_map[label] for label in target.nonzero()[0].tolist()] if len(target.nonzero()[0]) > 0 else [] for target in targets_array.round()]\n",
    "            \n",
    "            # Calculate Levenshtein distance\n",
    "            #print(pred_labels)\n",
    "            levenshtein_distance += calculate_levenshtein_distance(pred_labels, target_labels)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = test_correct / len(test_data)\n",
    "    average_levenshtein_distance = levenshtein_distance / len(test_data)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Average Levenshtein Distance: {average_levenshtein_distance:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-16T21:15:25.223979Z",
     "iopub.execute_input": "2023-06-16T21:15:25.224410Z",
     "iopub.status.idle": "2023-06-16T21:15:54.340474Z",
     "shell.execute_reply.started": "2023-06-16T21:15:25.224382Z",
     "shell.execute_reply": "2023-06-16T21:15:54.338108Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 85\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m#print('targets = ',targets)\u001B[39;00m\n\u001B[1;32m     84\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 85\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m#print('models output = ',outputs)\u001B[39;00m\n\u001B[1;32m     87\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[5], line 58\u001B[0m, in \u001B[0;36mASLModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     56\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x))\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m#x = self.dropout(x)\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m#x = self.dropout(x)\u001B[39;00m\n\u001B[1;32m     60\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc3(x)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
